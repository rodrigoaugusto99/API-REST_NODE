tsx - converter o codigo de ts pra js e executar o node nesse js, de forma 
automatizada e sem sujar as pastas(criando arquivos js)

dependencias instaladas nesse inicio:
"dependencies": {
    "fastify": "^4.26.2"
  },
  "devDependencies": {
    "@rocketseat/eslint-config": "^1.2.0",
    "@types/node": "^18.11.18",
    "eslint": "^8.33.0",
    "tsx": "^3.12.2",
    "typescript": "^4.9.5"
  }



vms usar o sqlite pois nao precisa de docker ou outra loucura, ele fica
ali numa pasta fisica

com node, podemos usar queryBuilder - construtor de querys
ele facilita a escrita das querys (dos codigos SQL), misturando com
javascriot.

exemplo, inves de fazer SELECT * FROM Users WHERE....
faremoz 
knex('users').where({
    first_name: 'Rodrigo',
    last_name: 'Augusto'
}).select('id')

se trocarmos de banco de dados, nao precisamos mudar esse codigo.
(pra outro banco que o knex suporte, claro.)

instalando knex e sqlite3
npm i knex sqlite3

ate p configurar eh mais facil, pois nao ha networkd connection, e sim, 
um filename, que eh o nome do arquivo q vms botar o banco

---------------------------------------

Agora que temos acesso ao banco de dados, precisamos ter:
tabelas, campos, chaves primeiras, estrangeiras, relaconamentos,
precisamos configurar td isso

Vamos fzr migrations!

sao controle de versao dentroi do nosso banco de dados.

eh importante para por exemplo, ta eu fazendo um parte do banco
e o outro fazendo outra parte. eh como se fosse o git, ta eu fazendo
uma parte do codigo, e ele outra. pra gente ficar no mesmo "lugar"
eu teria que enviar pra ele o meu codigo pra ele criar la tbm.
eu teria que mandar meu sql que fiz recentemente pro cara ter o banco 
atualizado. isso eh ruim.

migrations sao historico de tdoas as mudancas feitas no banco. Essas mudancas
sao sempre anotadas com a data e o horario que foram criadas. historico certinho.

o mais importante com as migrations eh que temos uma tabela criada automaticamente
chamada migrations. se tiver desatualziado pq outro alterou, basta rodarmos um comando pra atualizar.
eh exatamente o mesmo beneficio que o github tras pra gente com equipes de desenvovledores.

knex foi desenvolvido p ser desenvolvido com js, n ts.

convernsao - criar arquivo knexfile.js
vms criar knexfile.ts e pegar APENAS as configuracoes

temos que criar 

"knex": "node --no-warnings --loader tsx ./node_modules/.bin/knex",
--loader - p passar outra lib p carregar codigo node (tsx)
tsx pq entend ts
e dps, o caminho do binario do knex

npm run knex -h
dessa forma o -h eh pro npm run

p passar pro knex, tem que ser
npm run knex -- -h


import Knex from 'knex'

export const config: Knex.Config = {
  client: 'sqlite',
  connection: {
    filename: './db/app.db',
  },
  useNullAsDefault: true,
  migrations: {
    extension: 'ts',
    directory: './db/migrations',
  },
}

export const knex = Knex(config)

assim fico o arquivo de configuracao, o directory estamos mostrando aonde vai ficar a
pasta migratiosn quando fizermos uma migrations

o script fica assim:

 "knex": "node --no-warnings --import tsx ./node_modules/knex/bin/cli.js",
 tive que entrar na pasta do knex e achar o bin com o arquivo real
 antes tava ./node_modules/.bin/knex, e tava dando erro

 o comando vai ser:

 npm run knex -- migrate:make create-documents
(Created Migration: C:\documentos\projetos\web\rocketseat\formacao_node\ignite-node-02\db\migrations\20240421190131_create-transactions.ts)

-------------------------------------
na parte de criacao de tabelas, temos que usar uma sintaxe
exclusiva do knex, para que ele nao precise mudar qnd a gente
por ex trocar de sqlite opara postfrees, mysql, eetc

todo arquivo de migration, tem a data que foi criado certinho
e o nome do arquivo que informamos

tem o up - o que vai fazer.
tem o down - deu ruim! volta atras

-------------------------

npm run knex -- migrate:latest 

isso vai criar as tabelas. (Batch 1 run: 1 migrations)


knex.fn.now pra ser algo universal.
se for colocar tipo NOW() ou current_time sei la,
isso eh de um banco especifico, entao n estamos usando o knex direito,

podemos fazer uam outra migration, mas dessa vez n pra "criar", mas
pra podemos fzr uma migration que so adicionam ou alteram um campo

after id - pra colocar o campo embaixo do id
index - quer dizer q vms fzr muitas buscas em transacoes especificas
de uma transacao, entao session_id vai ser usado muito com where

-------------------------------
podemos ver as tabelas com o httpie no terminal, chamando
http localhost:3333/hello, por causa dessa rota que fizemos,
pra poder verificar se as tabelas foram criadas realmente

app.get('/hello', async () => {
  const tables = await knex('sqlite_schema').select('*')

  return tables
})

se quisermos restartar, criar do zero, temos que deletar a pasta 
app.db.

podemos tbm fzr essa verificao no beekeeper.
tabelas, campos, valores, inserir, excluir, dados

-------------------------
a ideia eh fazer mais rotas que fazem diferentes
operacoes no banco de dados, grande maioria de APIs sao isso,
rotas, portas de entrada p um usuario poder trabalhar com nosso banco
de dados, e com regras de negocio.

-----------------------------------

variaveis de ambiente - variaveis que sao diferentesd em cada ambiente

que estamos executando. ambiente- os momentos da app - desenvolvimento, producao, teste.
e existem informacoes que sao diferentes em cada ambiente.

por exemplo, banco de dados, em des eh um e em prod eh outro

pro arquivo env ser lido pelo node - npm i dotenv

fazer o .env com as variaveis de ambiente e n deixar subir com gitignore
fazer o .env.example e deixar subir no git p oturos desenolvedores verem e alterarem
de acordo com seu ambiente

---------------------------------------

temos que validar os valores de env para evitar que sejam preenchidas com valores
invalidos, oq causaria erro ao rodar o app (por exemplo, colocar um numero no lugar do
de uma string)


-------------------------------------
plugins do fastify - de rotas

criamos uma pasta pras rotas e colocamos a rota de transactions la.

o arquivo server.ts eh que vai importar as rotas, ou seja, nois vamos acoplar
pequenos funcionamentos a nossa funcao principal, que eh o app

testando - 

roda isso com http localhost:3333/hello do httpie
export async function transactionsRoutes(app: FastifyInstance) {
  app.get('/hello', async () => {
    const transactions = await knex('transactions').insert({
        id: 4,
        title: 'transacao teste x',
        amount: 3000,
    }).returning('*')

    return transactions
  })
}

dps roda isso pra printar
export async function transactionsRoutes(app: FastifyInstance) {
  app.get('/hello', async () => {
    const transactions = await knex('transactions')
      .where('amount', 3000)
      .select('*')

    return transactions
  })
}


---------------------

esse arquivo contem todas rotas sobre transactions, entao todas elas vao comecar
com /transactions, 
quando formos buscar todas as transacoes, vai ser /transactions
quando formps buscar por uma transaction especifica, /transactions/:id

entao vamos colocar prefixo la no arquivo principal quando
chamamos essa rota

agr, no app.get fica so o '/', sem precisar colocar transactions

- agora criando a rota POST
-body vem as informacoes que geralmente usamos p criar ou alterar algo,
geralmente elas vieram de um formulario por ex

request.body. ... o vscode nao ajude em nada.
NAo sabemos o que o frontend mandou ali.
entao vamos usar o zod p tipar

entao ao fazer o z.object e dps pegar o body dentro de um parse daquele schema,
estamos verificando se o body que veio do front respeita aquele schema

respeitar oq? se o title esta presente E eh uma string, mesma coisa pro amount e type.

o parse, se detectar algum erro, ele da um throw, ent n precisamos nos preocupar se essa
linha do parse nao passar, nada que ta embaixo vai ser executado por causa do throw

const body = createTransactionBodySchema.parse(
  request.body,
)

dessa forma, podemos ate desestruturar ele

const { title, amount, type } = createTransactionBodySchema.parse(
  request.body,
)


agora pegamos esses dados que vieram do frontend pelo body
e podemos fazer algo com o banco de dados, no caso, inserir, criar.

await knex('transactions').insert({
      id: randomUUID(),
      title,
      amount: type === 'credit' ? amount : amount * -1,
    })

colocamos o amount de acordo com o tipo de transacao, se for debito, 
colocamos como negativo, entao fica mais facil la na frente p somar todos
os valores

geralmente POST nao retorna nada, entao n vamos retornar o objeto que foi 
criado no banco, vamos sim retornar um status code. HTTP Codes que servem para
simbolizar o tipo de retorno da api, se deu sucesso ou erro, o tipo de erro/sucesso.

no caso, usaremos o 201, que eh p "recurso criado com sucesso."

Pra testarmos, com httpie fica mais chatinho, entao faremos com imnsonia

IMSNONIA -

-nova request collection
-nova pasta transactions
- na parte, nova requisicao do tipo POST, 
- chamremos a rota de http://localhost:3333/transactions
- trocamos o nome da requisicao para Create transaction

-no body, com json, enviamos os dados da transactions

se colocarmos creditx, ou seja, com o nome errado, vai dar erro 500, ou seja,
nao estamos tratando direitinho, realmente o zod trabalhou, nao chegou no 201, entao
nossa verificacao deu certo, 

pelos menos o zod nao ta deixando passar caso o usuario envie um valor incorreto.
mas temos que fazer um tratamento mais decente, mais pra frente.

podemos tipar o knex. na documentacao, ao procurar por typescript!

eh bom p deixar o knex mais esperto.

entao aqui nois podemos fazer uma interface, com transactions sendo a tabela,
e os dados, os campos. Agora, quando fizermos:
knex(''), ja vai sugir o transactions q eh uma tabela
e dentro de transactons, vai sugerir todos esses campos abaixo.

isso eh bom pra seguranca e manuntenabilidad no futuro.

declare module 'knex/types/tables' {
  export interface Tables {
    transactions: {
      id: string
      title: string
      amount: number
      created_at: string
      session_id?: string
    }
  }
}

--------------------------------------

get para todos as transactions e para uma so

pra todos - return { transactions }
como um objeto pq ai se for apenas return transactions,
vai retornar uma lista com varios objetos de transactions.
mas se for entre chaves, como objeto, vai ser um objeto grandao
que dentro dele tem uma lista chamada transactions, contendo ai sim
todas as transactions. e ai, se quisermos retornar outra informacao 
no futuro, basta colocar dentro do objeto, que ai vai ficar 
{
"outro objeto": 200,
"transactions": [ {}, {}, {} ]
}

pra um so - antes de fazer a busca no banco, temos que saber
qual eh o id do usuario. 
-pegar do request.params
-validar com zod
-ai sim fazer a busca.

-------------------
get para o resumo das transacoes (a soma de todas as colunas amount)
knex('transactions') - tabela transactions
.sum('amount' - soma todas as colunas amount
, { as: 'amount' }) - no response, o nome vai ser amount(antes tava
um nome esquisito pq a gnete nao tinha posto "nome" pra tabela)
.first() - pois knex retorna lista, entao pegar o first (sempre vai ser um so msm)

-------------------------------
estamos so com backend, nao temos frontend, ou seja, nao temos sistema de autenticacao,
de token, nao temos tabela de usuario, nao temos login por email etc.

mas mesmo assim podemos anotar quem eh o usuario que esta fazendo aquelas requisicoes.

cookies. Quando usuario criar a primeira transacao, que eh onde comeca tudo,
entao vamos anotar um session_id nos cookies.

npm i @fastify/cookie

-register cookie antes do register transactionRoutes.

logica no POST - 
se tiver sessionId, manda ele tbm la no insert.

se nao tiver, entra naquele if, e criamos um com o randomUUID.
e pra salvar esse sessionId nos cookies com o setCookie: 
reply.setCookie('sessionId', sessionId, {
  path: '/',
  maxAge: 1000 * 60 * 60 * 24 * 7, // 7 days
})

path - '/', entao todas as rotas terao acesso
maxAge - data de expiracao do cookie

pronto. Agora quando fizermos um post, automaticamente entrara la um sessionId,
que tbm seria automaticamente colocado nos cookies do navegador, e do imnsonia tbm.

cookies sao como parametros, mas sao criados pela propria aplicacao e enviados
automaticamente em todas as requisicoes.











